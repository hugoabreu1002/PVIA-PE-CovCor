{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import AdaBoostRegressor as ADA\n",
    "from sklearn.ensemble import BaggingRegressor as BAG\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.linear_model import RANSACRegressor as RAN\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor as PAR\n",
    "from sklearn.linear_model import SGDRegressor as SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  2%|▏         | 1/50 [00:00<00:32,  1.52it/s]\n",
      "  4%|▍         | 2/50 [00:01<00:32,  1.48it/s]\n",
      "  6%|▌         | 3/50 [00:02<00:31,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  -0.0012201155652138418\n",
      "first derivative:  0.0012201155652138418\n",
      "featness:  7.235882632629755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 4/50 [00:02<00:29,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative:  0.0012201155652138418\n",
      "first derivative:  0.0\n",
      "featness:  7.238322863760183\n",
      "7.235882632629755\n"
     ]
    }
   ],
   "source": [
    "class ensemble_search:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test,\n",
    "                 size_pop=20, epochs=5, verbose=True):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.size_pop = size_pop\n",
    "        self.epochs = epochs\n",
    "        self.fitness_array_ = np.array([])\n",
    "        self.best_of_all_ = None\n",
    "        self.verbose_ = verbose\n",
    "\n",
    "    def gen_population(self):\n",
    "        \n",
    "        population = [[]]*self.size_pop\n",
    "        \n",
    "        for i in range(self.size_pop):\n",
    "            \n",
    "            qt_regressor = np.random.randint(2,9)\n",
    "            lista_LR = ['LR',LR(), {}]\n",
    "            \n",
    "            lista_RFR = ['RFR',RFR(), \n",
    "                         {'n_estimators':np.random.randint(1,100),\n",
    "                          'max_depth':np.random.randint(1,20),\n",
    "                          'min_samples_split':np.random.randint(2,5),      \n",
    "                          'min_samples_leaf':np.random.randint(2,10),   \n",
    "                          'min_weight_fraction_leaf':np.random.rand(1)[0]/2}]\n",
    "            \n",
    "            lista_SVR = ['SVR',SVR(),\n",
    "                         {'kernel':random.choice(['linear','rbf','poly','sigmoid']),     \n",
    "                          'epsilon':np.random.rand(1)[0]/4,\n",
    "                          'C':random.choice([1,10,100,1000]),'gamma':'auto'}]\n",
    "            \n",
    "            lista_ADA = ['ADA',ADA(), \n",
    "                         {'n_estimators':np.random.randint(1,50)}]\n",
    "            \n",
    "            lista_BAG = ['BAG',BAG(), \n",
    "                         {'n_estimators':np.random.randint(1,50),'max_samples':np.random.randint(1,20)}]\n",
    "            \n",
    "            lista_GBR = ['GBR',GBR(), \n",
    "                         {'n_estimators':np.random.randint(1,100),'max_depth':np.random.randint(1,20),        \n",
    "                          'min_samples_split':np.random.randint(2,5),      \n",
    "                          'min_samples_leaf':np.random.randint(2,10),     \n",
    "                          'min_weight_fraction_leaf':np.random.rand(1)[0]/2}]\n",
    "            \n",
    "            lista_RAN = ['RAN',RAN(), {}]\n",
    "            \n",
    "            lista_PAR = ['PAR',PAR(), \n",
    "                         {'C': np.random.randint(1,10), 'early_stopping':True,        \n",
    "                          'n_iter_no_change':np.random.randint(1,10)}]\n",
    "            \n",
    "            lista_SGD = ['SGD',SGD(), {}]\n",
    "            \n",
    "            lista_regressors = [lista_LR,lista_RFR,lista_SVR,lista_ADA,lista_BAG,\n",
    "                                lista_GBR,lista_RAN,lista_PAR,lista_SGD]\n",
    "            \n",
    "            random.shuffle(lista_regressors)\n",
    "            \n",
    "            lista_regressors = lista_regressors[0:qt_regressor]\n",
    "            \n",
    "            for j in range(len(lista_regressors)):\n",
    "                lista_regressors[j][1] = lista_regressors[j][1].set_params(**lista_regressors[j][2])\n",
    "\n",
    "            population[i] = [qt_regressor, lista_regressors, 'voting_regressor', np.inf]\n",
    "            \n",
    "        return population\n",
    "\n",
    "    def set_fitness(self, population):\n",
    "        for i in range(len(population)):\n",
    "            \n",
    "            lista_tuplas_VR = []\n",
    "            nomes = []\n",
    "            for indv in population[i][1]:\n",
    "                \n",
    "                while indv[0] in nomes: #adionar X se o nome já estiver dentro\n",
    "                    indv[0] = indv[0]+'X'\n",
    "                nomes.append(indv[0])\n",
    "                \n",
    "                lista_tuplas_VR.append((indv[0],indv[1])) #aqui vai pegando cada regressor do indivíduo (lista de regressores),\n",
    "                                                          #que é formado pelo nome do regressor e o objeto.\n",
    "                \n",
    "            Voting_regressor = VotingRegressor(lista_tuplas_VR)\n",
    "            Voting_regressor.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            mae_vr = mae(Voting_regressor.predict(self.X_test), self.y_test)\n",
    "            population[i][-1] = mae_vr\n",
    "            population[i][-2] = Voting_regressor\n",
    "            \n",
    "        return population\n",
    "    \n",
    "    def next_population(self, population):\n",
    "        \n",
    "        for i in range(1, int(len(population)/2)):\n",
    "            qt_regs_pai1 = population[i][0]\n",
    "            qt_regs_pai2 = population[2*i][0]\n",
    "            \n",
    "            #aqui mistura os regressores\n",
    "            if qt_regs_pai1<=qt_regs_pai2:    \n",
    "                population[i][1][:int(qt_regs_pai1/2)] = population[2*i][1][:int(qt_regs_pai1/2)]\n",
    "            else:\n",
    "                population[i][1][:int(qt_regs_pai2/2)] = population[2*i][1][:int(qt_regs_pai2/2)]\n",
    "                \n",
    "            #modificar nomes dos regressores se houver repetido\n",
    "            nomes = []\n",
    "            for reg in population[i][1]:\n",
    "                while reg[0] in nomes: #adionar X se o nome já estiver dentro\n",
    "                    reg[0] = reg[0]+'X'\n",
    "                nomes.append(reg[0])\n",
    "        \n",
    "        return population\n",
    "    \n",
    "    def early_stop(self):\n",
    "        array = self.fitness_array_\n",
    "        to_break=False\n",
    "        if len(array) > 4:\n",
    "            array_diff1_1 = array[1:] - array[:-1]\n",
    "            array_diff2 = array_diff1_1[1:] - array_diff1_1[:-1]\n",
    "            \n",
    "            if (self.verbose_):\n",
    "                print('second derivative: ', array_diff2[-2:].mean()) \n",
    "                print('first derivative: ', abs(array_diff1_1[-2:].mean()))\n",
    "                print('featness: ', array[-1])\n",
    "                \n",
    "            if (array_diff2[-2:].mean()) > 0 and (abs(array_diff1_1[-3:].mean()) <1e-3):\n",
    "                to_break = True\n",
    "        \n",
    "        return to_break\n",
    "\n",
    "    def search_best(self):\n",
    "        population = self.gen_population()\n",
    "        population = self.set_fitness(population)\n",
    "        population.sort(key = lambda x: x[-1])  \n",
    "        self.fitness_array_ = np.append(self.fitness_array_, population[0][-1])\n",
    "        self.best_of_all_ = population[0][-2]\n",
    "        \n",
    "        for i in tqdm(range(self.epochs)):\n",
    "            population = self.next_population(population)\n",
    "            population = self.set_fitness(population)\n",
    "            population.sort(key = lambda x: x[-1])\n",
    "            \n",
    "            #pegar o melhor de todas as épocas\n",
    "            \n",
    "            if population[0][-1] < min(self.fitness_array_):\n",
    "                self.best_of_all_ = population[0][-2]\n",
    "            \n",
    "            #adicionar ao array de fitness o atual\n",
    "            self.fitness_array_ = np.append(self.fitness_array_, population[0][-1])\n",
    "\n",
    "            if self.early_stop():\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "\n",
    "\n",
    "n_samples = 1000\n",
    "n_outliers = 50\n",
    "X, y, coef = make_regression(n_samples=n_samples, n_features=1,n_informative=1, noise=10,coef=True, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "Ensearch = ensemble_search(X_train, y_train, X_test, y_test, size_pop=10, epochs=50).search_best()\n",
    "print(mae(Ensearch.best_of_all_.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
